ELK Stack on Kubernetes (ECK) å®‰è£…æ‰‹å†Œ
https://img.shields.io/badge/ECK-2.11.0-blue
https://img.shields.io/badge/Kubernetes-1.24%252B-brightgreen
https://img.shields.io/badge/License-MIT-yellow

ä½¿ç”¨ Elastic Cloud on Kubernetes (ECK) åœ¨ Kubernetes é›†ç¾¤ä¸Šéƒ¨ç½² Elasticsearchã€Kibana å’Œ Filebeatï¼Œæ­å»ºç”Ÿäº§å¯ç”¨çš„æ—¥å¿—ç›‘æ§ç³»ç»Ÿã€‚æœ¬æŒ‡å—åŒ…å«è¯¦ç»†æ­¥éª¤ã€é¿å‘æŒ‡å—åŠç”Ÿäº§ç¯å¢ƒå»ºè®®ã€‚

ğŸ“– ç›®å½•
æ¶æ„æ¦‚è¿°

å‰ç½®æ¡ä»¶

å¿«é€Ÿå¼€å§‹

1. å®‰è£… ECK Operator

2. é…ç½® NFS æŒä¹…åŒ–å­˜å‚¨

3. éƒ¨ç½² Elasticsearch

4. éƒ¨ç½² Kibana å¹¶é…ç½® Ingress HTTPS

5. éƒ¨ç½² Filebeat é‡‡é›†å®¹å™¨æ—¥å¿—

éªŒè¯ä¸æµ‹è¯•

å¸¸è§é—®é¢˜ä¸æ’æŸ¥

é…ç½®é€ŸæŸ¥è¡¨

å¸è½½

è´¡çŒ®æŒ‡å—

è®¸å¯è¯

æ¶æ„æ¦‚è¿°
plain
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Ingress/Nginx  â”‚â”€â”€â”€â”€â–¶â”‚     Kibana      â”‚â”€â”€â”€â”€â–¶â”‚ Elasticsearch   â”‚
â”‚  (HTTPS: 443)   â”‚     â”‚   (Port: 5601)  â”‚     â”‚   (Port: 9200)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â–²
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚    Filebeat     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ (DaemonSeté‡‡é›†) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NFS Storage    â”‚â—„â”€â”€ æŒä¹…åŒ–å­˜å‚¨ Elasticsearch æ•°æ®
â”‚ (192.168.100.100)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ECK Operatorï¼šç®¡ç† Elasticsearchã€Kibana ç­‰èµ„æºçš„ç”Ÿå‘½å‘¨æœŸã€‚

Elasticsearchï¼šæ—¥å¿—å­˜å‚¨ä¸æ£€ç´¢ï¼Œæ•°æ®æŒä¹…åŒ–åˆ° NFSã€‚

Kibanaï¼šæ—¥å¿—å¯è§†åŒ–ï¼Œé€šè¿‡ Ingress HTTPS å¯¹å¤–æš´éœ²ã€‚

Filebeatï¼šä»¥ DaemonSet æ–¹å¼è¿è¡Œåœ¨æ¯ä¸ªèŠ‚ç‚¹ï¼Œé‡‡é›†å®¹å™¨æ—¥å¿—ã€‚

NFSï¼šæä¾›å…±äº«å­˜å‚¨ï¼Œç¡®ä¿ ES æ•°æ®é«˜å¯ç”¨ï¼ˆç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨æ›´å¯é çš„å­˜å‚¨å¦‚ Cephã€äº‘ç›˜ç­‰ï¼‰ã€‚

å‰ç½®æ¡ä»¶
ç»„ä»¶	ç‰ˆæœ¬/è¦æ±‚	è¯´æ˜
Kubernetes é›†ç¾¤	1.24+	å»ºè®®ä½¿ç”¨ç”Ÿäº§çº§é›†ç¾¤
ECK Operator	2.11.0	æœ¬æ‰‹å†ŒåŸºäºè¯¥ç‰ˆæœ¬
NFS æœåŠ¡å™¨	ä»»ä½•æ”¯æŒ NFS çš„ç³»ç»Ÿ	ç”¨äº ES æŒä¹…åŒ–ï¼ŒIP éœ€é›†ç¾¤å†…å¯è¾¾
Ingress Controller	nginx-ingress	ç”¨äºæš´éœ² Kibana
å­˜å‚¨ç±»	æ”¯æŒ ReadWriteOnce çš„åŠ¨æ€å­˜å‚¨	æœ¬ç¤ºä¾‹ä½¿ç”¨ NFS Client Provisioner
âš ï¸ æ³¨æ„ï¼šç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨äº‘æœåŠ¡å•†æä¾›çš„å—å­˜å‚¨ï¼ˆå¦‚ AWS EBSã€GCE PDï¼‰æˆ–ä¸“ç”¨å­˜å‚¨ç³»ç»Ÿï¼Œé¿å… NFS å•ç‚¹æ•…éšœå’Œæ€§èƒ½ç“¶é¢ˆã€‚

å¿«é€Ÿå¼€å§‹
1. å®‰è£… ECK Operator
bash
# å®‰è£…è‡ªå®šä¹‰èµ„æºå®šä¹‰ (CRD)
kubectl create -f https://download.elastic.co/downloads/eck/2.11.0/crds.yaml

# å®‰è£… Operator
kubectl apply -f https://download.elastic.co/downloads/eck/2.11.0/operator.yaml

# éªŒè¯å®‰è£…
kubectl get pods -n elastic-system
ğŸ’¡ æç¤ºï¼šOperator é»˜è®¤èµ„æºè¯·æ±‚è¾ƒé«˜ï¼Œè‹¥é›†ç¾¤èµ„æºç´§å¼ ï¼Œå¯ä¸‹è½½ YAML åè°ƒæ•´ resources å­—æ®µå†åº”ç”¨ã€‚

2. é…ç½® NFS æŒä¹…åŒ–å­˜å‚¨
2.1 å‡†å¤‡ NFS æœåŠ¡å™¨
åœ¨ NFS æœåŠ¡å™¨ï¼ˆå‡è®¾ IP 192.168.100.100ï¼‰ä¸Šæ‰§è¡Œï¼š

bash
mkdir -p /root/data/es-storage
chmod 777 /root/data/es-storage
echo "/root/data/es-storage *(rw,sync,no_root_squash)" >> /etc/exports
exportfs -r
2.2 éƒ¨ç½² NFS Client Provisioner
æ–‡ä»¶ï¼šnfs-rbac.yamlï¼ˆRBAC æƒé™ï¼‰

yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nfs-client-provisioner
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nfs-client-provisioner-runner
rules:
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create", "update", "patch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: run-nfs-client-provisioner
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    namespace: kube-system
roleRef:
  kind: ClusterRole
  name: nfs-client-provisioner-runner
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: leader-locking-nfs-client-provisioner
  namespace: kube-system
rules:
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: leader-locking-nfs-client-provisioner
  namespace: kube-system
subjects:
  - kind: ServiceAccount
    name: nfs-client-provisioner
    namespace: kube-system
roleRef:
  kind: Role
  name: leader-locking-nfs-client-provisioner
  apiGroup: rbac.authorization.k8s.io
æ–‡ä»¶ï¼šnfs-storageclass.yamlï¼ˆè®¾ä¸ºé»˜è®¤ StorageClassï¼‰

yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: nfs-client
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
provisioner: k8s-sigs.io/nfs-subdir-external-provisioner
parameters:
  archiveOnDelete: "false"
reclaimPolicy: Retain
volumeBindingMode: Immediate
æ–‡ä»¶ï¼šnfs-deployment.yamlï¼ˆProvisioner éƒ¨ç½²ï¼‰

yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-client-provisioner
  namespace: kube-system
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: nfs-client-provisioner
  template:
    metadata:
      labels:
        app: nfs-client-provisioner
    spec:
      serviceAccountName: nfs-client-provisioner
      containers:
        - name: nfs-client-provisioner
          image: k8s.gcr.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2
          volumeMounts:
            - name: nfs-client-root
              mountPath: /persistentvolumes
          env:
            - name: PROVISIONER_NAME
              value: k8s-sigs.io/nfs-subdir-external-provisioner
            - name: NFS_SERVER
              value: 192.168.100.100        # âš ï¸ æ›¿æ¢ä¸ºä½ çš„ NFS æœåŠ¡å™¨ IP
            - name: NFS_PATH
              value: /root/data/es-storage  # âš ï¸ æ›¿æ¢ä¸ºä½ çš„å…±äº«è·¯å¾„
      volumes:
        - name: nfs-client-root
          nfs:
            server: 192.168.100.100         # âš ï¸ æ›¿æ¢
            path: /root/data/es-storage     # âš ï¸ æ›¿æ¢
åº”ç”¨é…ç½®ï¼š

bash
kubectl apply -f nfs-rbac.yaml
kubectl apply -f nfs-storageclass.yaml
kubectl apply -f nfs-deployment.yaml

# éªŒè¯
kubectl get sc                 # åº”çœ‹åˆ° nfs-client ä¸”æ ‡è®°ä¸º default
kubectl get pods -n kube-system | grep nfs
3. éƒ¨ç½² Elasticsearch
åˆ›å»ºå‘½åç©ºé—´ logï¼Œå¹¶éƒ¨ç½² ES å®ä¾‹ã€‚

æ–‡ä»¶ï¼šelasticsearch.yaml

yaml
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: quickstart
  namespace: log
spec:
  version: 8.15.0
  nodeSets:
  - name: default
    count: 1
    config:
      node.store.allow_mmap: false   # é¿å… mmap æ£€æŸ¥ï¼Œé€‚åˆ NFS
    podTemplate:
      spec:
        containers:
        - name: elasticsearch
          resources:
            requests:
              memory: "1Gi"
              cpu: "500m"
            limits:
              memory: "1.5Gi"         # æ ¹æ®èŠ‚ç‚¹èµ„æºè°ƒæ•´
              cpu: "1"
          env:
          - name: ES_JAVA_OPTS
            value: "-Xms512m -Xmx512m"  # JVM å †å¤§å°ï¼Œä¸è¶…è¿‡å†…å­˜ limits çš„ 50%
    volumeClaimTemplates:
    - metadata:
        name: elasticsearch-data
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 5Gi                # æ ¹æ®éœ€è¦è°ƒæ•´
        storageClassName: nfs-client
éƒ¨ç½²ï¼š

bash
kubectl create namespace log
kubectl apply -f elasticsearch.yaml

# ç­‰å¾…å°±ç»ªï¼ˆçº¦ 2-3 åˆ†é’Ÿï¼‰
kubectl get elasticsearch -n log
kubectl get pods -n log -w
ğŸ” è·å– elastic ç”¨æˆ·å¯†ç ï¼ˆç™»å½• Kibana ç”¨ï¼‰ï¼š

bash
kubectl get secret -n log quickstart-es-elastic-user -o go-template='{{.data.elastic | base64decode}}'
4. éƒ¨ç½² Kibana å¹¶é…ç½® Ingress HTTPS
4.1 éƒ¨ç½² Kibana
æ–‡ä»¶ï¼škibana.yaml

yaml
apiVersion: kibana.k8s.elastic.co/v1
kind: Kibana
metadata:
  name: quickstart
  namespace: log
spec:
  version: 8.15.0
  count: 1
  elasticsearchRef:
    name: quickstart
  http:
    service:
      spec:
        type: ClusterIP
        ports:
        - port: 5601
          targetPort: 5601
4.2 ç”Ÿæˆ TLS è¯ä¹¦ï¼ˆæµ‹è¯•ç¯å¢ƒï¼‰
bash
openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
  -keyout kibana.key -out kibana.crt \
  -subj "/CN=kibana.lim.com" \
  -addext "subjectAltName=DNS:kibana.lim.com"

kubectl create secret tls kibana-tls \
  --cert=kibana.crt --key=kibana.key -n log
âš ï¸ ç”Ÿäº§ç¯å¢ƒï¼šå»ºè®®ä½¿ç”¨æ­£è§„ CA ç­¾å‘çš„è¯ä¹¦ï¼Œæˆ–é›†æˆ cert-manager è‡ªåŠ¨ç®¡ç†ã€‚

4.3 é…ç½® Ingress
æ–‡ä»¶ï¼šingress.yaml

yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: kibana-ingress
  namespace: log
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"   # å…³é”®ï¼šåç«¯ä½¿ç”¨ HTTPS
    nginx.ingress.kubernetes.io/proxy-ssl-verify: "false"   # å¿½ç•¥åç«¯è¯ä¹¦éªŒè¯
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - kibana.lim.com
    secretName: kibana-tls
  rules:
  - host: kibana.lim.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: quickstart-kb-http     # ECK è‡ªåŠ¨ç”Ÿæˆçš„ Service å
            port:
              number: 5601
éƒ¨ç½²ï¼š

bash
kubectl apply -f kibana.yaml
kubectl apply -f ingress.yaml

# éªŒè¯
kubectl get ingress -n log
kubectl get pods -n log
ç°åœ¨å¯é€šè¿‡ https://kibana.lim.com è®¿é—® Kibanaï¼Œä½¿ç”¨ elastic ç”¨æˆ·å’Œä¹‹å‰è·å–çš„å¯†ç ç™»å½•ã€‚

5. éƒ¨ç½² Filebeat é‡‡é›†å®¹å™¨æ—¥å¿—
æ–‡ä»¶ï¼šfilebeat.yaml

yaml
apiVersion: beat.k8s.elastic.co/v1beta1
kind: Beat
metadata:
  name: quickstart
  namespace: log
spec:
  type: filebeat
  version: 8.15.0
  elasticsearchRef:
    name: quickstart
  config:
    filebeat.inputs:
    - type: container
      paths:
      - /var/log/containers/*.log
      processors:
      - add_kubernetes_metadata:
          in_cluster: true
  daemonSet:
    podTemplate:
      spec:
        automountServiceAccountToken: true
        securityContext:
          runAsUser: 0                     # ä»¥ root è¿è¡Œï¼Œç¡®ä¿è¯»æƒé™
        containers:
        - name: filebeat
          resources:
            requests:
              memory: "100Mi"
              cpu: "100m"
            limits:
              memory: "200Mi"
              cpu: "200m"
          volumeMounts:
          - name: varlogcontainers
            mountPath: /var/log/containers
          - name: varlogpods
            mountPath: /var/log/pods
          - name: varlibdockercontainers
            mountPath: /var/lib/docker/containers
          - name: data
            mountPath: /usr/share/filebeat/data
        volumes:
        - name: varlogcontainers
          hostPath:
            path: /var/log/containers
        - name: varlogpods
          hostPath:
            path: /var/log/pods
        - name: varlibdockercontainers
          hostPath:
            path: /var/lib/docker/containers
        - name: data
          emptyDir: {}                      # ä¸´æ—¶å­˜å‚¨ï¼Œé¿å…æƒé™é—®é¢˜
ğŸ” æ³¨æ„ï¼šå¦‚æœä½ çš„èŠ‚ç‚¹ä½¿ç”¨ containerd è¿è¡Œæ—¶ï¼Œ/var/lib/docker/containers å¯èƒ½ä¸å­˜åœ¨ã€‚è¯·æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´æŒ‚è½½è·¯å¾„ã€‚é€šå¸¸ containerd çš„æ—¥å¿—ä½äº /var/log/podsï¼Œå¯ä»¥åªæŒ‚è½½å‰ä¸¤ä¸ªè·¯å¾„ã€‚

éƒ¨ç½²ï¼š

bash
kubectl apply -f filebeat.yaml

# éªŒè¯æ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰ Filebeat Pod
kubectl get pods -n log -o wide | grep filebeat
éªŒè¯ä¸æµ‹è¯•
æ£€æŸ¥æ‰€æœ‰ Pod çŠ¶æ€

bash
kubectl get pods -n log
æœŸæœ›æ‰€æœ‰ Pod å‡ä¸º Running çŠ¶æ€ã€‚

æŸ¥çœ‹ Elasticsearch å¥åº·çŠ¶æ€

bash
kubectl get elasticsearch -n log
è¾“å‡ºä¸­ HEALTH åº”ä¸º green æˆ– yellowã€‚

åœ¨ Kibana ä¸­æŸ¥çœ‹æ—¥å¿—

è®¿é—® https://kibana.lim.com

ç™»å½•åè¿›å…¥ "Discover" é¡µé¢ï¼Œåˆ›å»ºç´¢å¼•æ¨¡å¼ï¼ˆå¦‚ filebeat-*ï¼‰ï¼Œå³å¯çœ‹åˆ°å®¹å™¨æ—¥å¿—ã€‚

æ‰‹åŠ¨ç”Ÿæˆæµ‹è¯•æ—¥å¿—

bash
kubectl run test-logger --image=busybox --restart=Never -- sh -c "echo 'Hello ELK' && sleep 5"
ç¨ååœ¨ Kibana ä¸­æœç´¢ "Hello ELK" ç¡®è®¤æ—¥å¿—è¢«é‡‡é›†ã€‚

å¸¸è§é—®é¢˜ä¸æ’æŸ¥
âŒ Filebeat ä¸æ–­é‡å¯
åŸå› ï¼š/usr/share/filebeat/data ç›®å½•æ— å†™å…¥æƒé™ã€‚

è§£å†³ï¼šä½¿ç”¨ emptyDir å·æŒ‚è½½åˆ°è¯¥ç›®å½•ï¼ˆå·²åœ¨é…ç½®ä¸­æä¾›ï¼‰ã€‚

âŒ Filebeat æ— æ³•é‡‡é›†æ—¥å¿—
åŸå› ï¼šå®¹å™¨è¿è¡Œæ—¶è·¯å¾„ä¸åŒ¹é…ã€‚

æ£€æŸ¥ï¼š

bash
# ç™»å½•èŠ‚ç‚¹ï¼ŒæŸ¥çœ‹å®é™…æ—¥å¿—è·¯å¾„
ls /var/log/containers
ls /var/log/pods
ls /var/lib/docker/containers   # ä»… docker è¿è¡Œæ—¶å­˜åœ¨
è§£å†³ï¼šæ ¹æ®å®é™…è·¯å¾„è°ƒæ•´ hostPath æŒ‚è½½ã€‚

âŒ Kibana Ingress è®¿é—®ç©ºç™½/æ— æ³•åŠ è½½
åŸå› ï¼šIngress åç«¯åè®®æœªé…ç½®ä¸º HTTPSï¼Œæˆ–æœªè·³è¿‡è¯ä¹¦éªŒè¯ã€‚

è§£å†³ï¼šæ·»åŠ æ³¨è§£ï¼š

yaml
nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
nginx.ingress.kubernetes.io/proxy-ssl-verify: "false"
âŒ ImagePullBackOff
å¯èƒ½åŸå› ï¼šé›†ç¾¤èŠ‚ç‚¹é•œåƒä»“åº“æºä¸ä¸€è‡´ï¼Œå¯¼è‡´æŸäº›èŠ‚ç‚¹æ‰¾ä¸åˆ°é•œåƒã€‚

ä¸´æ—¶è§£å†³ï¼šç™»å½•é—®é¢˜èŠ‚ç‚¹æ‰‹åŠ¨æ‹‰å–é•œåƒï¼š

bash
docker pull k8s.gcr.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2
# æˆ– crictl pull ...
é•¿æœŸæ–¹æ¡ˆï¼šç»Ÿä¸€æ‰€æœ‰èŠ‚ç‚¹çš„å®¹å™¨è¿è¡Œæ—¶é…ç½®ï¼Œæˆ–ä½¿ç”¨ç§æœ‰é•œåƒä»“åº“ï¼ˆå¦‚ Harborï¼‰ç¼“å­˜é•œåƒã€‚

âŒ Elasticsearch å¯åŠ¨å¤±è´¥ï¼ˆmmap ç›¸å…³ï¼‰
åŸå› ï¼šNFS ä¸æ”¯æŒ mmapã€‚

è§£å†³ï¼šåœ¨ ES é…ç½®ä¸­è®¾ç½® node.store.allow_mmap: falseã€‚

âŒ Elasticsearch å†…å­˜ä¸è¶³
åŸå› ï¼šæœªè®¾ç½® ES_JAVA_OPTS é™åˆ¶å †å†…å­˜ã€‚

è§£å†³ï¼šæ·»åŠ ç¯å¢ƒå˜é‡ -Xms512m -Xmx512mï¼Œå¹¶ç¡®ä¿ limits å†…å­˜è¶³å¤Ÿã€‚

é…ç½®é€ŸæŸ¥è¡¨
é—®é¢˜/éœ€æ±‚	é…ç½®é¡¹/å‘½ä»¤	ä½ç½®
ES å †å†…å­˜é™åˆ¶	ES_JAVA_OPTS: "-Xms512m -Xmx512m"	elasticsearch.yaml
ES å­˜å‚¨ç±»	storageClassName: nfs-client	elasticsearch.yaml
Kibana Ingress åç«¯åè®®	nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"	ingress.yaml
Kibana æœåŠ¡å	quickstart-kb-http (ECK è‡ªåŠ¨ç”Ÿæˆ)	ingress.yaml
Filebeat ä»¥ root è¿è¡Œ	securityContext.runAsUser: 0	filebeat.yaml
Filebeat ä¸´æ—¶å­˜å‚¨	emptyDir: {} æŒ‚è½½åˆ° /usr/share/filebeat/data	filebeat.yaml
è·å– elastic å¯†ç 	kubectl get secret -n log quickstart-es-elastic-user -o go-template='{{.data.elastic | base64decode}}'	å‘½ä»¤è¡Œ
å¸è½½
bash
# åˆ é™¤ Filebeat
kubectl delete -f filebeat.yaml

# åˆ é™¤ Kibana å’Œ Ingress
kubectl delete -f ingress.yaml
kubectl delete -f kibana.yaml

# åˆ é™¤ Elasticsearch
kubectl delete -f elasticsearch.yaml

# åˆ é™¤ NFS Provisioner
kubectl delete -f nfs-deployment.yaml
kubectl delete -f nfs-storageclass.yaml
kubectl delete -f nfs-rbac.yaml

# åˆ é™¤å‘½åç©ºé—´ï¼ˆå¯é€‰ï¼‰
kubectl delete namespace log

# å¸è½½ ECK Operator
kubectl delete -f https://download.elastic.co/downloads/eck/2.11.0/operator.yaml
kubectl delete -f https://download.elastic.co/downloads/eck/2.11.0/crds.yaml
âš ï¸ åˆ é™¤ PVC å‰è¯·ç¡®è®¤æ•°æ®å·²å¤‡ä»½ï¼ŒPVC åˆ é™¤å NFS ä¸Šçš„æ•°æ®å¯èƒ½ä¸¢å¤±ã€‚

è´¡çŒ®æŒ‡å—
æ¬¢è¿æäº¤ Issue å’Œ PR æ”¹è¿›æœ¬æŒ‡å—ã€‚åœ¨è´¡çŒ®å‰è¯·ç¡®ä¿ï¼š

æ›´æ–°å†…å®¹ä¸å½“å‰ ECK ç‰ˆæœ¬å…¼å®¹ã€‚

æ·»åŠ æˆ–ä¿®æ”¹éƒ¨åˆ†éœ€é™„ä¸Šè¯´æ˜ã€‚

ä¿æŒ Markdown æ ¼å¼æ¸…æ™°ã€‚

è®¸å¯è¯
MIT Â© 2025
